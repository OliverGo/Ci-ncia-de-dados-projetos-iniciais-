Princípios éticos e diretrizes

Imagine que uma empresa de tecnologia está criando um sistema de IA para analisar currículos e recomendar os melhores candidatos para contratação. Durante os testes, percebe-se que o sistema favorece homens em relação a mulheres para cargos de liderança, mesmo quando ambos os grupos têm qualificações similares.

O problema que está ocorrendo está relacionado com o gênero ou seja os dados que foram utilizados para treinar essa IA podem está desiguais. Ou seja há mais dados de homens que exerceram cargos de lideranças fazendo com que o modelo relacione competência com gênero da pessoa, gerando assim preconceitos.
O problema está relacionado com o principio de justiça, ou seja o modelo vai sempre classificar mais homens que mulheres de forma injusta.

Como resolver?

Deve-se equilibra os dados, para gera equidade, ou seja, no treinamento desse modelo deve haver a mesma quantidade de homens e mulheres com cargos de liderança, para que assim a IA entenda que a competência não deve se relacionar com o gênero dos entrevistados.
Além disso deve-se garantir a diversidades dos dados, para que outros grupos não sejam injustiçados da mesma forma.
É necessário garantir a imparcialidade dos dados fazendo com que o modelo não utilize métricas como: raça, cor ou gênero 